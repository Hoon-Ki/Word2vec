{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25000 labeled train reviews, 25000 labeled test reviews, \n",
      "and 50000 unlabeled reviews\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "train = pd.read_csv( \"data/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "test = pd.read_csv( \"data/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "unlabeled_train = pd.read_csv( \"data/unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "# 데이터 행개수 확인 (총 100,000 개)\n",
    "print ((\"Read {0} labeled train reviews, {1} labeled test reviews, \"+ '\\n' +\"and {2} unlabeled reviews\").format(train[\"review\"].size, test[\"review\"].size, unlabeled_train[\"review\"].size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16490, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn1neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"kitchen\"].shape  # kitchen이 one-hot이 아닌 distributed representation 된 matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5,  0.5,  0.5],\n",
       "       [ 0.5,  0.5,  0.5,  0.5,  0.5],\n",
       "       [ 0.5,  0.5,  0.5,  0.5,  0.5],\n",
       "       ..., \n",
       "       [ 0.5,  0.5,  0.5,  0.5,  0.5],\n",
       "       [ 0.5,  0.5,  0.5,  0.5,  0.5],\n",
       "       [ 0.5,  0.5,  0.5,  0.5,  0.5]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.divide(np.ones((300,5),dtype=\"float32\"),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec에서 각 리뷰안의 각 단어들의 embedding matrix(가중치 matrix)를 모두 합해 평균내어 각 리뷰마다 하나의 대표값을 만들었는데, 이는 평균값이 나중에는 피쳐벡터중에서 하나의 피쳐가 된다. 즉 해당 리뷰에 대한 고유의 피쳐값을 구하는 이 과정은, CNN의 convolution layer에서 흑백이미지의 피쳐를 뽑은 후 average pooling 하는 과정과 상당히 유사함을 알수가 있다. CNN에서 하나의 피쳐맵은 input 사진의 특정부분을 잘 구분하는 가중곱의 합이 되어진 convolved 피쳐는 word2vec에서 input과 input vector를 곱한 방식과 유사하고 (정확히 같지는 않다.그냥 가중곱을 하여 다른 공간에 사영시킨다는 측면에서는 유사하다는 것이 포인트) 다음 average pooling 을 하여 기존 피쳐맵을 줄이는 과정은 평균을 통해 피쳐안의 피쳐를 뽑겠다는 말인데 , 이것이 word2vec에서도 한 리뷰안에서 embedding된 각 단어들의 matrix들의 평균을 내는 것과 유사하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality\n",
    "##min_word_count = 40   # Minimum word count\n",
    "#num_workers = 4       # Number of threads to run in parallel\n",
    "#context = 10          # Context window size\n",
    "#downsampling = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    # 주어진 문장의 단어벡터들의 평균을 계산하는 함수\n",
    "    \n",
    "    # 피쳐벡터 초기화(속도를 위해)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    \n",
    "    nwords = 0.\n",
    "    \n",
    "    # 모델의 vocabulary에 있는 단어들의 이름이 담긴 Index2word를 속도를 위해 set으로 바꾼다.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    # 각 리뷰에서 각 단어들에 대해 반복문을 돌린다,\n",
    "    # 만약 단어가 모형의 vocabulary안에 있다면 기존 피쳐벡터에 이 단어의 피쳐벡터(엠베딩된 단어 matrix)를 더한다.\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    \n",
    "    # 평균벡터을 얻기위해 단어들의 수로 피쳐벡터를 나눈다. \n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # 한 세트의 리뷰가 주어졌을때 (각 리뷰는 단어 리스트임, 결국 전체 구조는 리스트 속 리스트),\n",
    "    # 각 리뷰에 대한 평균피쳐벡터를 계산하여 2차원 numpy array를 반환해라\n",
    "    \n",
    "    # counter 초기화\n",
    "    counter = 0.\n",
    "    \n",
    "    # 속도를 위해, 미리 2차원 numpy array 할당.\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    \n",
    "    # 모든 리뷰마다 루프문 돌기\n",
    "    for review in reviews:\n",
    "       \n",
    "       # 매 1000번째 리뷰마다 상태메세지 프린트\n",
    "        if counter%1000. == 0.:\n",
    "            print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       \n",
    "        # 평균피쳐벡터들을 생성하는 makeFeatureVec 함수 호출\n",
    "        reviewFeatureVecs[int(counter)] = makeFeatureVec(review, model, num_features)\n",
    "    \n",
    "        # 카운터 1씩 증가.\n",
    "        counter = counter + 1.\n",
    "        \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # document를 list화\n",
    "    # 불용어를 없애는 것은 선택, 보통 높은 질의 워드벡터를 얻기 위해 불용어를 제거하지는 않음.\n",
    "    \n",
    "    # HTML 함수 지우기\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "      \n",
    "    # 글자가 아닌것들 없애기 []안의 ^는 not과 같음.\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    # 소문자화 후 띄어쓰기를 기준으로 모두 나눔.\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # 불용어 제거\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # 단어 리스트 반환\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCleanReviews(reviews):\n",
    "    clean_reviews = []\n",
    "    for review in reviews[\"review\"]:\n",
    "        clean_reviews.append(review_to_wordlist(review, remove_stopwords=True ))\n",
    "    return clean_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 170 of the file D:\\python\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "Creating average feature vecs for test reviews\n",
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# 위 함수들을 사용해, 트레이닝과 테스트셋을 위한 평균벡터들을 계산\n",
    "# stop word를 제거하는것 잊지 말기\n",
    "\n",
    "print (\"Creating average feature vecs for train reviews\")\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, remove_stopwords=True ))\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "\n",
    "print (\"Creating average feature vecs for test reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append(review_to_wordlist( review, remove_stopwords=True ))\n",
    "testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# 100개의 나무를 이용해 훈련셋을 랜덤포레스트에 적합.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n",
    "\n",
    "print (\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit( trainDataVecs, train[\"sentiment\"] )\n",
    "\n",
    "# 테스트 결과 할당\n",
    "result = forest.predict(testDataVecs)\n",
    "\n",
    "# 테스트 결과 추출\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_train = forest.predict(trainDataVecs)\n",
    "train_output = pd.DataFrame(data = {\"id\":train[\"id\"], \"sentiment\":result_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment\n",
       "0  \"5814_8\"          1\n",
       "1  \"2381_9\"          1\n",
       "2  \"7759_3\"          0\n",
       "3  \"3630_4\"          0\n",
       "4  \"9495_8\"          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(train_output[\"sentiment\"], train[\"sentiment\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
